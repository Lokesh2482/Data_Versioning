1.Create a git repo and clone it in local
2.Create mycode.py and add code to it (It will sace a csv file to a new "data" folder)
3.Do a git add commit push before initializing DVC
4.pip install DVC
5.Now we do "dvc init"(creates .dvcignore,.dvc)
6.Now do "mkdir S3" (creates a new S3 directory, we will do this later on AWS as well)
7.Now we do "dvc remote add -d <name> S3"(COMMAND to tell DVC the remote origin)
8.next "dvc add data"(everytime a data is committed, dvc is responsible to track changes made in the data file)
Now it will ask to do: ("git rm -r --cached 'data'" and "git commit -m "stop tracking data"")
Because initially we were tracking data/ folder from git so now we remove it for DVC to handle.
9.Again we do "dvc add data/" (creates data.dvc) then "git add .gitignore data.dvc"(for git to keep tracking and not forget, this is done to keep git upto date)
10.Now - "dvc commit" and then "dvc push"(2 files pushed : 1 file with the unique md5 id and other the data itself)
11.git add commit push to mark the stage as the first version of data(we will roll back here if required in future)
12.Now make changes to mycode.py to append a new row in data, check changes via "dvc status"
13.Again - - "dvc commit" and then "dvc push"
14.Then git add-commit-push (we're saving V2 of our data at this point)
15.Check dvc/git status, everything should be upto date.

16. Lets say alice doesnt want to be with any of the two gfs he made, he wants to stay single so for that what we have to do is that we have to roll back to the previous version of the data that is the first version of the data. This is one of the most important step for data versioning.
